{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import itertools \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers, optimizers, applications\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import MaxPool2D, Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import VGG19, MobileNetV2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, precision_recall_curve\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16-based CNN Model\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# create datasets for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model similar to VGG16\n",
    "def vgg16(input_shape):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),  \n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'), \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Flatten(),\n",
    "        Dense(units=4096, activation='relu'),\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "model_1 = vgg16((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_43 (Conv2D)          (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 256, 256, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 128, 128, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 128, 128, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 64, 64, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 64, 64, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 32, 32, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 32, 32, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 16, 16, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 16, 16, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 8, 8, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              134221824 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,636,801\n",
      "Trainable params: 143,633,857\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_1.compile(optimizer = Adam(lr=0.001), \n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_vgg16/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_vgg16/log.csv')\n",
    "log_dir = \"./logs/log_vgg16/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/99 [====>.........................] - ETA: 41:38 - loss: 38.1820 - accuracy: 0.6581 - auc_2: 0.5179 - auc_3: 0.8154 - precision_1: 0.8159 - recall_1: 0.7455"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history_1 = model_1.fit_generator(generator = train_generator,\n",
    "                               steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                               validation_data = valid_generator,\n",
    "                               validation_steps = STEP_SIZE_VALID,\n",
    "                               epochs = 16,\n",
    "                               callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for trasining testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "def cnn(input_shape):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(3, 3)),\n",
    "        Conv2D(filters=32, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Dropout(0.2), \n",
    "        MaxPool2D(pool_size=(3, 3)),\n",
    "        Flatten(),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dropout(0.25),     \n",
    "        Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "model_2 = cnn((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_53 (Conv2D)          (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 256, 256, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 85, 85, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 85, 85, 32)        2080      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 85, 85, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 42, 42, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 42, 42, 64)        8256      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 42, 42, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 21, 21, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                200736    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 285,409\n",
      "Trainable params: 285,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_2.compile(optimizer = Adam(lr=0.001), \n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_cnn/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_cnn/log.csv')\n",
    "log_dir = \"./logs/log_cnn/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_2 = model_2.fit_generator(generator = train_generator,\n",
    "                                  steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                  validation_data = valid_generator,\n",
    "                                  validation_steps = STEP_SIZE_VALID,\n",
    "                                  epochs = 9,\n",
    "                                  callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for training testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 creation\n",
    "cnn_base = ResNet50(include_top = False,\n",
    "                    weights = \"imagenet\",\n",
    "                    input_shape = (256, 256, 3))\n",
    "model_3 = models.Sequential()\n",
    "model_3.add(cnn_base)\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(units = 64, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(units = 128, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 256, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 128, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "cnn_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8388672   \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,050,753\n",
      "Trainable params: 8,463,041\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_3.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = Adam(lr = 0.001),\n",
    "              metrics = ['accuracy', tf.metrics.Precision(), tf.metrics.Recall(), tf.metrics.AUC(), tf.metrics.AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss', \n",
    "                              verbose = 1, \n",
    "                              mode = 'min', \n",
    "                              patience = 4)\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_resnet/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "log_dir = \"./logs/log_resnet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')\n",
    "csv_logger = CSVLogger('./logs/log_resnet/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_3 = model_3.fit_generator(generator = train_generator,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = STEP_SIZE_VALID,\n",
    "                             epochs = 15,\n",
    "                             callbacks = [lr_reduction, earlyStopping, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for trasining testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (227, 227),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (227, 227),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (227, 227),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "model_4 = Sequential([\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_57 (Conv2D)          (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 55, 55, 96)       384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 27, 27, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 27, 27, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 13, 13, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 13, 13, 384)      1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 13, 13, 384)      1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 13, 13, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,290,945\n",
      "Trainable params: 58,288,193\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile model\n",
    "model_4.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = Adam(lr = 0.001),\n",
    "               metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_alexnet_2/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "log_dir = \"./logs/log_alexnet_2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')\n",
    "csv_logger = CSVLogger('./logs/log_alexnet_2/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_4 = model_4.fit_generator(generator = train_generator,\n",
    "                               steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                               validation_data = valid_generator,\n",
    "                               validation_steps = STEP_SIZE_VALID,\n",
    "                               epochs = 12,\n",
    "                               callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 159\n",
      "STEP_SIZE_VALID: 40\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# generate datasets\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (224, 224),\n",
    "        batch_size = 10,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 10,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (224, 224),\n",
    "        class_mode = 'binary',\n",
    "        batch_size = 1,\n",
    "        seed = 42,\n",
    "        shuffle = False)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 6s 0us/step\n",
      "80150528/80134624 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# construct model\n",
    "vgg_19 = VGG19(include_top = False, \n",
    "               weights = 'imagenet', \n",
    "               input_shape = (224, 224, 3))\n",
    "\n",
    "vgg_19.trainable = False\n",
    "\n",
    "model_5 = Sequential([\n",
    "    vgg_19,\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_5.compile(optimizer = Adam(lr = 0.001),\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_vgg19/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_vgg19/log.csv')\n",
    "log_dir = \"./logs/log_vgg19/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_5 = model_5.fit_generator(generator = train_generator,\n",
    "                                  steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                  validation_data = valid_generator,\n",
    "                                  validation_steps = STEP_SIZE_VALID,\n",
    "                                  epochs = 10,\n",
    "                                  callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# create datasets for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (224, 224),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base model for transfer learning\n",
    "base_model = MobileNetV2(\n",
    "    input_shape = (224, 224, 3),\n",
    "    include_top = False, \n",
    "    weights = 'imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezes all neurons for base model\n",
    "base_model.trainable = False \n",
    "# construct model\n",
    "model_6 = Sequential([ \n",
    "    base_model,\n",
    "    Conv2D(32, 3, activation = 'relu'), \n",
    "    Dropout(0.2), \n",
    "    GlobalAveragePooling2D(), \n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 5, 5, 32)          368672    \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 32)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,689\n",
      "Trainable params: 368,705\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_6.compile(\n",
    "    optimizer = Adam(lr = 0.001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_mobilenet/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_mobilenet/log.csv')\n",
    "log_dir = \"./logs/log_mobilenet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.8086 - precision_12: 0.8118 - recall_12: 0.9945 - auc_24: 0.6321 - auc_25: 0.8686\n",
      "Epoch 00001: saving model to ../logs/log_mobilenet/model.01-0.41.hdf5\n",
      "99/99 [==============================] - 358s 4s/step - loss: 0.5042 - accuracy: 0.8086 - precision_12: 0.8118 - recall_12: 0.9945 - auc_24: 0.6321 - auc_25: 0.8686 - val_loss: 0.4073 - val_accuracy: 0.8125 - val_precision_12: 0.8125 - val_recall_12: 1.0000 - val_auc_24: 0.7964 - val_auc_25: 0.9377 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.8143 - precision_12: 0.8143 - recall_12: 1.0000 - auc_24: 0.7822 - auc_25: 0.9331\n",
      "Epoch 00002: saving model to ../logs/log_mobilenet/model.02-0.39.hdf5\n",
      "99/99 [==============================] - 335s 3s/step - loss: 0.4051 - accuracy: 0.8143 - precision_12: 0.8143 - recall_12: 1.0000 - auc_24: 0.7822 - auc_25: 0.9331 - val_loss: 0.3946 - val_accuracy: 0.8125 - val_precision_12: 0.8125 - val_recall_12: 1.0000 - val_auc_24: 0.8022 - val_auc_25: 0.9409 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8168 - precision_12: 0.8171 - recall_12: 0.9984 - auc_24: 0.8143 - auc_25: 0.9457\n",
      "Epoch 00003: saving model to ../logs/log_mobilenet/model.03-0.41.hdf5\n",
      "99/99 [==============================] - 353s 4s/step - loss: 0.3811 - accuracy: 0.8168 - precision_12: 0.8171 - recall_12: 0.9984 - auc_24: 0.8143 - auc_25: 0.9457 - val_loss: 0.4065 - val_accuracy: 0.8125 - val_precision_12: 0.8125 - val_recall_12: 1.0000 - val_auc_24: 0.8231 - val_auc_25: 0.9479 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model_6.fit_generator(generator = train_generator,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = STEP_SIZE_VALID,\n",
    "                             epochs = 3,\n",
    "                             callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2afb1a226ae99d3db0944d8cc6d3a1f2e0f53bd7b948e5881598cb61b32f648a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
