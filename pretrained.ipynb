{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import itertools \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers, optimizers, applications\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import MaxPool2D, Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import VGG19, MobileNetV2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, precision_recall_curve\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16-based CNN Model\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model similar to VGG16\n",
    "def vgg16(input_shape):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),  \n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'), \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Flatten(),\n",
    "        Dense(units=4096, activation='relu'),\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "model_1 = vgg16((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_1.compile(optimizer = Adam(lr=0.001), \n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_vgg16/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_vgg16/log.csv')\n",
    "log_dir = \"./logs/log_vgg16/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_1 = model_1.fit_generator(generator = train_generator,\n",
    "                               steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                               validation_data = valid_generator,\n",
    "                               validation_steps = STEP_SIZE_VALID,\n",
    "                               epochs = 5,\n",
    "                               callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "{'0_not_mel': 0, '1_mel': 1}\n",
      "{'0_not_mel': 0, '1_mel': 1}\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for trasining testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(train_generator.class_indices)\n",
    "print(valid_generator.class_indices)\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "def cnn(input_shape):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(3, 3)),\n",
    "        Conv2D(filters=32, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Dropout(0.2), \n",
    "        MaxPool2D(pool_size=(3, 3)),\n",
    "        Flatten(),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dropout(0.25),     \n",
    "        Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "model_2 = cnn((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256, 256, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 85, 85, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 85, 85, 32)        2080      \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 85, 85, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 42, 42, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 42, 42, 64)        8256      \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 42, 42, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 21, 21, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                200736    \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 285,409\n",
      "Trainable params: 285,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_2.compile(\n",
    "    optimizer = Adam(lr = 0.001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_cnn/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_cnn/log.csv')\n",
    "log_dir = \"./logs/log_cnn/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.8073 - precision_8: 0.1000 - recall_8: 0.0034 - auc_16: 0.5151 - auc_17: 0.1890\n",
      "Epoch 00001: saving model to ./logs/log_cnn/model.01-0.55.hdf5\n",
      "99/99 [==============================] - 377s 4s/step - loss: 0.5050 - accuracy: 0.8073 - precision_8: 0.1000 - recall_8: 0.0034 - auc_16: 0.5151 - auc_17: 0.1890 - val_loss: 0.5470 - val_accuracy: 0.8125 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_auc_16: 0.5778 - val_auc_17: 0.2305 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.8130 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5339 - auc_17: 0.2102\n",
      "Epoch 00002: saving model to ./logs/log_cnn/model.02-0.52.hdf5\n",
      "99/99 [==============================] - 330s 3s/step - loss: 0.4952 - accuracy: 0.8130 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5339 - auc_17: 0.2102 - val_loss: 0.5249 - val_accuracy: 0.8125 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_auc_16: 0.5576 - val_auc_17: 0.2449 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.8124 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5389 - auc_17: 0.2295\n",
      "Epoch 00003: saving model to ./logs/log_cnn/model.03-0.58.hdf5\n",
      "99/99 [==============================] - 366s 4s/step - loss: 0.4905 - accuracy: 0.8124 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5389 - auc_17: 0.2295 - val_loss: 0.5779 - val_accuracy: 0.8125 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_auc_16: 0.5805 - val_auc_17: 0.2487 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.8124 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5379 - auc_17: 0.2170\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00004: saving model to ./logs/log_cnn/model.04-0.53.hdf5\n",
      "99/99 [==============================] - 296s 3s/step - loss: 0.4925 - accuracy: 0.8124 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5379 - auc_17: 0.2170 - val_loss: 0.5264 - val_accuracy: 0.8125 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_auc_16: 0.5769 - val_auc_17: 0.2479 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.8124 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5435 - auc_17: 0.2330\n",
      "Epoch 00005: saving model to ./logs/log_cnn/model.05-0.54.hdf5\n",
      "99/99 [==============================] - 332s 3s/step - loss: 0.4836 - accuracy: 0.8124 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_16: 0.5435 - auc_17: 0.2330 - val_loss: 0.5395 - val_accuracy: 0.8125 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_auc_16: 0.6036 - val_auc_17: 0.2640 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history_2 = model_2.fit_generator(generator = train_generator,\n",
    "                                  steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                  validation_data = valid_generator,\n",
    "                                  validation_steps = STEP_SIZE_VALID,\n",
    "                                  epochs = 5,\n",
    "                                  callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for training testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 creation\n",
    "cnn_base = ResNet50(include_top = False,\n",
    "                    weights = \"imagenet\",\n",
    "                    input_shape = (256, 256, 3))\n",
    "model_3 = models.Sequential()\n",
    "model_3.add(cnn_base)\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(units = 64, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(units = 128, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 256, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 128, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "cnn_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8388672   \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,050,753\n",
      "Trainable params: 8,463,041\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_3.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = Adam(lr = 0.001),\n",
    "              metrics = ['accuracy', tf.metrics.Precision(), tf.metrics.Recall(), tf.metrics.AUC(), tf.metrics.AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss', \n",
    "                              verbose = 1, \n",
    "                              mode = 'min', \n",
    "                              patience = 4)\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_resnet/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "log_dir = \"./logs/log_resnet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')\n",
    "csv_logger = CSVLogger('./logs/log_resnet/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.9001 - accuracy: 0.7821 - precision_10: 0.2299 - recall_10: 0.0671 - auc_20: 0.4715 - auc_21: 0.1800\n",
      "Epoch 00001: saving model to ./logs/log_resnet/model.01-0.50.hdf5\n",
      "99/99 [==============================] - 603s 6s/step - loss: 0.9001 - accuracy: 0.7821 - precision_10: 0.2299 - recall_10: 0.0671 - auc_20: 0.4715 - auc_21: 0.1800 - val_loss: 0.5027 - val_accuracy: 0.8125 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00 - val_auc_20: 0.5000 - val_auc_21: 0.1875 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.8136 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.5106 - auc_21: 0.1904\n",
      "Epoch 00002: saving model to ./logs/log_resnet/model.02-0.48.hdf5\n",
      "99/99 [==============================] - 464s 5s/step - loss: 0.4858 - accuracy: 0.8136 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.5106 - auc_21: 0.1904 - val_loss: 0.4831 - val_accuracy: 0.8125 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00 - val_auc_20: 0.5000 - val_auc_21: 0.1875 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.8130 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.5194 - auc_21: 0.2019\n",
      "Epoch 00003: saving model to ./logs/log_resnet/model.03-0.48.hdf5\n",
      "99/99 [==============================] - 499s 5s/step - loss: 0.4832 - accuracy: 0.8130 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.5194 - auc_21: 0.2019 - val_loss: 0.4827 - val_accuracy: 0.8125 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00 - val_auc_20: 0.5015 - val_auc_21: 0.1880 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.8117 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.4617 - auc_21: 0.1744\n",
      "Epoch 00004: saving model to ./logs/log_resnet/model.04-0.48.hdf5\n",
      "99/99 [==============================] - 483s 5s/step - loss: 0.4907 - accuracy: 0.8117 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.4617 - auc_21: 0.1744 - val_loss: 0.4789 - val_accuracy: 0.8150 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00 - val_auc_20: 0.5000 - val_auc_21: 0.1850 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8136 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.4924 - auc_21: 0.1808\n",
      "Epoch 00005: saving model to ./logs/log_resnet/model.05-0.48.hdf5\n",
      "99/99 [==============================] - 607s 6s/step - loss: 0.4857 - accuracy: 0.8136 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_20: 0.4924 - auc_21: 0.1808 - val_loss: 0.4827 - val_accuracy: 0.8125 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00 - val_auc_20: 0.5000 - val_auc_21: 0.1875 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history_3 = model_3.fit_generator(generator = train_generator,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = STEP_SIZE_VALID,\n",
    "                             epochs = 5,\n",
    "                             callbacks = [lr_reduction, earlyStopping, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for trasining testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (227, 227),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (227, 227),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (227, 227),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "model_4 = Sequential([\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 55, 55, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 27, 27, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 13, 13, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,290,945\n",
      "Trainable params: 58,288,193\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile model\n",
    "model_4.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = Adam(lr = 0.001),\n",
    "               metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_alexnet_2/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "log_dir = \"./logs/log_alexnet_2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')\n",
    "csv_logger = CSVLogger('./logs/log_alexnet_2/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_4 = model_4.fit_generator(generator = train_generator,\n",
    "                               steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                               validation_data = valid_generator,\n",
    "                               validation_steps = STEP_SIZE_VALID,\n",
    "                               epochs = 12,\n",
    "                               callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate datasets\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (224, 224),\n",
    "        batch_size = 10,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 10,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (224, 224),\n",
    "        class_mode = 'binary',\n",
    "        batch_size = 1,\n",
    "        seed = 42,\n",
    "        shuffle = False)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "vgg_19 = VGG19(include_top = False, \n",
    "               weights = 'imagenet', \n",
    "               input_shape = (224, 224, 3))\n",
    "\n",
    "vgg_19.trainable = False\n",
    "\n",
    "model_5 = Sequential([\n",
    "    vgg_19,\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_5.compile(optimizer = Adam(lr = 0.001),\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_vgg19/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_vgg19/log.csv')\n",
    "log_dir = \"./logs/log_vgg19/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_5 = model_5.fit_generator(generator = train_generator,\n",
    "                                  steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                  validation_data = valid_generator,\n",
    "                                  validation_steps = STEP_SIZE_VALID,\n",
    "                                  epochs = 5,\n",
    "                                  callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (224, 224),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base model for transfer learning\n",
    "base_model = MobileNetV2(\n",
    "    input_shape = (224, 224, 3),\n",
    "    include_top = False, \n",
    "    weights = 'imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezes all neurons for base model\n",
    "base_model.trainable = False \n",
    "# construct model\n",
    "model_6 = Sequential([ \n",
    "    base_model,\n",
    "    Conv2D(32, 3, activation = 'relu'), \n",
    "    Dropout(0.2), \n",
    "    GlobalAveragePooling2D(), \n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_6.compile(\n",
    "    optimizer = Adam(lr = 0.001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_mobilenet/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_mobilenet/log.csv')\n",
    "log_dir = \"./logs/log_mobilenet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model_6.fit_generator(generator = train_generator,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = STEP_SIZE_VALID,\n",
    "                             epochs = 5,\n",
    "                             callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2afb1a226ae99d3db0944d8cc6d3a1f2e0f53bd7b948e5881598cb61b32f648a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
