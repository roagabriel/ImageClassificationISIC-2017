{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import itertools \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers, optimizers, applications\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import MaxPool2D, Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import VGG19, MobileNetV2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, precision_recall_curve\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16-based CNN Model\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# create datasets for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model similar to VGG16\n",
    "def vgg16(input_shape):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),  \n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'), \n",
    "        Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        Flatten(),\n",
    "        Dense(units=4096, activation='relu'),\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "model_1 = vgg16((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              134221824 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,636,801\n",
      "Trainable params: 143,633,857\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_1.compile(optimizer = Adam(lr=0.001), \n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_vgg16/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_vgg16/log.csv')\n",
    "log_dir = \"./logs/log_vgg16/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_1 = model_1.fit_generator(generator = train_generator,\n",
    "                               steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                               validation_data = valid_generator,\n",
    "                               validation_steps = STEP_SIZE_VALID,\n",
    "                               epochs = 5,\n",
    "                               callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "{'0_not_mel': 0, '1_mel': 1}\n",
      "{'0_not_mel': 0, '1_mel': 1}\n",
      "STEP_SIZE_TRAIN: 399\n",
      "STEP_SIZE_VALID: 100\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for trasining testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 4,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 4,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(train_generator.class_indices)\n",
    "print(valid_generator.class_indices)\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "def cnn(input_shape):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(3, 3)),\n",
    "        Conv2D(filters=32, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Dropout(0.2), \n",
    "        MaxPool2D(pool_size=(3, 3)),\n",
    "        Flatten(),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dropout(0.25),     \n",
    "        Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "model_2 = cnn((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256, 256, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 85, 85, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 85, 85, 32)        2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 85, 85, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 42, 42, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 42, 42, 64)        8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 42, 42, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 21, 21, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 21, 21, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                200736    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 285,409\n",
      "Trainable params: 285,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_2.compile(\n",
    "    optimizer = Adam(lr = 0.01),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_cnn/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_cnn/log.csv')\n",
    "log_dir = \"./logs/log_cnn/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_2 = model_2.fit_generator(generator = train_generator,\n",
    "                                  steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                  validation_data = valid_generator,\n",
    "                                  validation_steps = STEP_SIZE_VALID,\n",
    "                                  epochs = 10,\n",
    "                                  callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for training testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (256, 256),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 creation\n",
    "cnn_base = ResNet50(include_top = False,\n",
    "                    weights = \"imagenet\",\n",
    "                    input_shape = (256, 256, 3))\n",
    "model_3 = models.Sequential()\n",
    "model_3.add(cnn_base)\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(units = 64, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(units = 128, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 256, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 128, activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "cnn_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8388672   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,050,753\n",
      "Trainable params: 8,463,041\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_3.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = Adam(lr = 0.001),\n",
    "              metrics = ['accuracy', tf.metrics.Precision(), tf.metrics.Recall(), tf.metrics.AUC(), tf.metrics.AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss', \n",
    "                              verbose = 1, \n",
    "                              mode = 'min', \n",
    "                              patience = 4)\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_resnet/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "log_dir = \"./logs/log_resnet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')\n",
    "csv_logger = CSVLogger('./logs/log_resnet/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_3 = model_3.fit_generator(generator = train_generator,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = STEP_SIZE_VALID,\n",
    "                             epochs = 5,\n",
    "                             callbacks = [lr_reduction, earlyStopping, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# Set path for trasining testing and validation\n",
    "# Data Generator for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (227, 227),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (227, 227),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (227, 227),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "model_4 = Sequential([\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 55, 55, 96)       384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 27, 27, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 13, 13, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,290,945\n",
      "Trainable params: 58,288,193\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile model\n",
    "model_4.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = Adam(lr = 0.001),\n",
    "               metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_alexnet_2/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "log_dir = \"./logs/log_alexnet_2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')\n",
    "csv_logger = CSVLogger('./logs/log_alexnet_2/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_4 = model_4.fit_generator(generator = train_generator,\n",
    "                               steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                               validation_data = valid_generator,\n",
    "                               validation_steps = STEP_SIZE_VALID,\n",
    "                               epochs = 12,\n",
    "                               callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 159\n",
      "STEP_SIZE_VALID: 40\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# generate datasets\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (224, 224),\n",
    "        batch_size = 10,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 10,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (224, 224),\n",
    "        class_mode = 'binary',\n",
    "        batch_size = 1,\n",
    "        seed = 42,\n",
    "        shuffle = False)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "vgg_19 = VGG19(include_top = False, \n",
    "               weights = 'imagenet', \n",
    "               input_shape = (224, 224, 3))\n",
    "\n",
    "vgg_19.trainable = False\n",
    "\n",
    "model_5 = Sequential([\n",
    "    vgg_19,\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_5.compile(optimizer = Adam(lr = 0.001),\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_vgg19/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_vgg19/log.csv')\n",
    "log_dir = \"./logs/log_vgg19/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history_5 = model_5.fit_generator(generator = train_generator,\n",
    "                                  steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                  validation_data = valid_generator,\n",
    "                                  validation_steps = STEP_SIZE_VALID,\n",
    "                                  epochs = 5,\n",
    "                                  callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Architecture\n",
    "\n",
    "## Generating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "STEP_SIZE_TRAIN: 99\n",
      "STEP_SIZE_VALID: 25\n",
      "STEP_SIZE_TEST: 600\n"
     ]
    }
   ],
   "source": [
    "# create datasets for training, validation, and testing\n",
    "train_fldr = './split/train'\n",
    "val_fldr = './split/val'\n",
    "test_fldr = './split/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_fldr,\n",
    "        target_size = (224, 224),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary',\n",
    "        seed = 42)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_fldr, \n",
    "        target_size = (224, 224),\n",
    "        batch_size = 1,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False,\n",
    "        seed = 42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "print(f'STEP_SIZE_TRAIN: {STEP_SIZE_TRAIN}')\n",
    "print(f'STEP_SIZE_VALID: {STEP_SIZE_VALID}')\n",
    "print(f'STEP_SIZE_TEST: {STEP_SIZE_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base model for transfer learning\n",
    "base_model = MobileNetV2(\n",
    "    input_shape = (224, 224, 3),\n",
    "    include_top = False, \n",
    "    weights = 'imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezes all neurons for base model\n",
    "base_model.trainable = False \n",
    "# construct model\n",
    "model_6 = Sequential([ \n",
    "    base_model,\n",
    "    Conv2D(32, 3, activation = 'relu'), \n",
    "    Dropout(0.2), \n",
    "    GlobalAveragePooling2D(), \n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 5, 5, 32)          368672    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 32)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,689\n",
      "Trainable params: 368,705\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_6.compile(\n",
    "    optimizer = Adam(lr = 0.001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy', Precision(), Recall(), AUC(), AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_mobilenet/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_mobilenet/log.csv')\n",
    "log_dir = \"./logs/log_mobilenet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model_6.fit_generator(generator = train_generator,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = STEP_SIZE_VALID,\n",
    "                             epochs = 30,\n",
    "                             callbacks = [lr_reduction, mcp_save, tensorboard_cb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1599 images belonging to 2 classes.\n",
      "Found 401 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "{'0_not_mel': 0, '1_mel': 1}\n"
     ]
    }
   ],
   "source": [
    "# generate dataset\n",
    "train_fldr = \"split/train\"\n",
    "val_fldr = \"split/val\"\n",
    "test_fldr = \"split/test\"\n",
    "\n",
    "tr_gen_imb = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_fldr,\n",
    "                                                                     class_mode = 'binary',\n",
    "                                                                     target_size = (224, 224),\n",
    "                                                                     batch_size = 16)\n",
    "val_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_fldr,\n",
    "                                                                        class_mode = 'binary', \n",
    "                                                                        target_size = (224, 224),\n",
    "                                                                        batch_size = 16)\n",
    "tt_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_fldr,\n",
    "                                                                       class_mode = 'binary',\n",
    "                                                                       target_size = (224, 224),\n",
    "                                                                       batch_size = 16)\n",
    "print(tr_gen_imb.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = next(tr_gen_imb)\n",
    "X_val, y_val = next(val_generator)\n",
    "X_tt, y_tt = next(tt_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_tr, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "def basic_incnn(input_shape):\n",
    "    return models.Sequential([\n",
    "        layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),   \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=256, activation='relu'),\n",
    "        layers.Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "model_7 = basic_incnn((224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 224, 224, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 112, 112, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 112, 112, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 56, 56, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 56, 56, 256)       73984     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 56, 56, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 28, 28, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 200704)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               51380480  \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,466,145\n",
      "Trainable params: 51,465,505\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_7.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001),\n",
    "              metrics = ['accuracy', tf.metrics.Precision(), tf.metrics.Recall(), tf.metrics.AUC(), tf.metrics.AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"./logs/log_incnn/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('./logs/log_incnn/log.csv')\n",
    "log_dir = \"./logs/log_incnn/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model_7.fit(tr_gen_imb,\n",
    "                   epochs = 10,\n",
    "                   validation_data = val_generator,\n",
    "                   callbacks = [lr_reduction, mcp_save, csv_logger])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2afb1a226ae99d3db0944d8cc6d3a1f2e0f53bd7b948e5881598cb61b32f648a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
